{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Setup"]},{"cell_type":"markdown","metadata":{},"source":["## Installs"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16807,"status":"ok","timestamp":1700649874437,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"GIoo5vcfiqpF","outputId":"b10a286b-4fd5-4420-8fdc-659a8072a6f7"},"outputs":[],"source":["# Segmentation\n","# ! pip install --upgrade mxnet\n","# ! pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n","# ! pip install --upgrade gluoncv\n","\n","# Edge detection\n","# ! conda install scikit-image\n","\n","# Depth estimation\n","# ! pip install -q transformers"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"elapsed":247,"status":"error","timestamp":1700649954416,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"qin4eTO9iKiG","outputId":"4c7e8c7c-34ef-49aa-aea1-ed9807fb3f8f"},"outputs":[],"source":["import numpy as np\n","import cv2\n","from os import listdir\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"attempted relative import with no known parent package","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2432\\2322657289.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import custom methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneral_methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msemantic_segmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0medge_detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdepth_estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"]}],"source":["# Import custom methods\n","import general_methods\n","import semantic_segmentation\n","import edge_detection\n","import depth_estimation\n","import geometry\n","import transforms"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get pre-trained models\n","seg_model = semantic_segmentation.get_pretrained_model()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pipeline(filename, wallpaper_filename):\n","    input_pil = general_methods.import_and_resize(filename)\n","    input_img = general_methods.import_mx_image(filename)\n","    input_cv2 = general_methods.import_cv2_image(filename)\n","    height = input_cv2.shape[0]\n","    width = input_cv2.shape[1]\n","    size = (width, height)\n","\n","    # Segmentation\n","    mmask = semantic_segmentation.get_segementation(input_img, seg_model)\n","    labels = general_methods.get_labels_string(mmask, mmask.shape[0])\n","    walls = general_methods.find_colour_indices(labels, \"0.47058824,0.47058824,0.47058824,1.0\")\n","    other = general_methods.find_not_colour_indices(labels, \"0.47058824,0.47058824,0.47058824,1.0\")\n","    segmented_input = semantic_segmentation.remove_inds(input_img, [other], [0, 0, 0])\n","\n","    ceiling_x, _ = np.where(labels == \"0.47058824,0.47058824,0.3137255,1.0\")\n","\n","    if ceiling_x.size > (0.05 * (height * width)):\n","        non_ceil_x, non_ceil_y = np.where((labels != \"0.47058824,0.47058824,0.47058824,1.0\") & (labels != \"0.47058824,0.47058824,0.3137255,1.0\"))\n","        non_ceil = np.array([non_ceil_x, non_ceil_y])\n","\n","        input_copy = np.ones((input_cv2.shape[0], input_cv2.shape[1], 3))\n","        input_copy = input_copy.astype(float)\n","        input_copy[non_ceil[0], non_ceil[1]] = np.array([255, 255, 255], dtype=float)\n","        input_copy[walls[0], walls[1]] = np.array([255, 255, 255], dtype=float)\n","        input_copy = np.clip(input_copy, 0, 255)\n","\n","        segmented_input_2 = input_copy.astype(np.uint8)\n","\n","        for i in range(input_cv2.shape[1]):\n","            for j in range(input_cv2.shape[0]-1, -1, -1):\n","                if np.array_equal(segmented_input_2[j][i], [1, 1, 1]):\n","                    segmented_input_2[:j, i] = np.array([1, 1, 1], dtype=float)\n","                    break\n","\n","        edge_map = edge_detection.detect_edges(segmented_input_2)\n","        edge_map = np.asarray(edge_map.convert(\"RGB\"))\n","\n","        hough_img = edge_detection.hough_transform(edge_map, input_cv2.shape[0], 10, 0.001, 0.5)\n","        corners = depth_estimation.get_harris_corners(hough_img)\n","        labels = general_methods.get_labels_string(corners, 40)\n","        red = general_methods.find_colour_indices(labels, \"255.0,0.0,0.0\")\n","        \n","        temp2 = corners.copy()\n","        temp2[red[0], red[1]] = np.array([0, 0, 0], dtype=float)\n","\n","        ceiling_colours = general_methods.get_labels_string(temp2, temp2.shape[0])\n","        _, ceiling_corners = np.where(ceiling_colours == \"255.0,0.0,0.0\")\n","        corner_inds = geometry.find_corners(ceiling_corners, ceiling_corners, width)\n","    else:\n","        # Depth estimation\n","        depth_image = depth_estimation.estimate_depth(input_pil)\n","\n","        # Edge detection\n","        edge_map = edge_detection.detect_edges(input_cv2)\n","        segmented_edges = edge_detection.get_segmented_edges(edge_map, walls)\n","\n","        # Find corners\n","        hough_img = edge_detection.hough_transform(segmented_edges, height, 50, 0.03, 0.02)\n","        vertical_lines = edge_detection.get_vertical_lines(hough_img)\n","        hough_colours = general_methods.get_labels_string(vertical_lines, vertical_lines.shape[0])\n","        hough_corners = edge_detection.get_hough_corners(hough_colours)\n","        mean_depth = depth_estimation.get_mean_depths(depth_image, other)\n","        matrix = general_methods.get_matrix(mean_depth)\n","        matrix_corners = depth_estimation.get_harris_corners(matrix)\n","        harris_colours = general_methods.get_labels_string(matrix_corners, matrix_corners.shape[0])\n","        _, harris_corners = np.where(harris_colours == \"255,0,0\")\n","        corner_inds = geometry.find_corners(hough_corners, harris_corners, width)\n","    \n","    only_walls = geometry.create_wall_corner_map(segmented_input, other, walls, corner_inds)\n","\n","    # Find room geometry\n","    contours = geometry.find_contours(only_walls)\n","    corner_adj_geom = geometry.find_walls(contours, corner_inds)\n","    new_geom = geometry.find_quadrilaterals(corner_adj_geom, width)\n","    new_corner_geom = geometry.move_edges_to_corners(new_geom, corner_inds)\n","\n","    # Perspective transform\n","    wallpaper = general_methods.import_cv2_image(wallpaper_filename)\n","    result_1, result_2 = transforms.get_transformed_wallpaper(new_corner_geom, height, width, size, wallpaper)\n","\n","    # Create final image\n","    final_mask = transforms.get_wall_mask(new_corner_geom, height, width, walls)\n","    final_output_1, final_output_2 = transforms.combine_wallpaper_and_input(input_cv2, final_mask, result_1, result_2, walls)\n"," \n","    return final_output_1, final_output_2\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Loop over all images in input folder\n","# folder_dir = \"images/inputs/rooms/small-test-set\"\n","# wallpaper_filename = \"images/inputs/wallpaper/check-even.jpg\"\n"," \n","# for image in listdir(folder_dir):\n","#     if image[0] >= 'a':\n","#         filename = \"images/inputs/rooms/small-test-set/\" + image\n","#         final_output_1, final_output_2 = pipeline(filename, wallpaper_filename)\n","#         cv2.imwrite(\"images/outputs/final-outputs/check-for-breaking/\" + image, final_output_1)\n","#         # cv2.imwrite(\"images/outputs/final-outputs/test-set/simple-\" + image, final_output_2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filename = \"images/inputs/rooms/test-set/bedroom-4.jpg\"\n","wallpaper_filename = \"images/inputs/wallpaper/check-even.jpg\"\n","final_output_1, final_output_2 = pipeline(filename, wallpaper_filename)\n","cv2.imwrite(\"images/outputs/final-outputs/bedroom-4.jpg\", final_output_1)\n","# cv2.imwrite(\"images/outputs/final-outputs/simple-empty6.jpg\", final_output_2)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
