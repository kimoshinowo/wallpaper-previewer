{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Analysis\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy as sp\n",
    "import statsmodels as sm\n",
    "from scipy.stats import wilcoxon, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_input = pd.read_csv(\"data-collection/outputs/performance-data-true-false.csv\")\n",
    "df_ft_input = pd.read_csv(\"data-collection/outputs/performance-data-false-true.csv\")\n",
    "df_ff_input = pd.read_csv(\"data-collection/outputs/performance-data-false-false.csv\")\n",
    "\n",
    "df_gt_input = pd.read_csv(\"data-collection/groundtruths/target-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare number of corners found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kim\\anaconda3\\envs\\analysis\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Add column to each DF saying how many corners are not Nan\n",
    "df_tf = df_tf_input[[\"filename\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "df_ff = df_ff_input[[\"filename\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "df_gt = df_gt_input[[\"filename\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "\n",
    "df_tf = df_tf.replace('FAILED', np.nan, regex=True)\n",
    "df_ff = df_ff.replace('FAILED', np.nan, regex=True)\n",
    "\n",
    "df_tf[\"tf-num-corners\"] = df_tf.count(axis=1)-1\n",
    "df_ff[\"ff-num-corners\"] = df_ff.count(axis=1)-1\n",
    "df_gt[\"gt-num-corners\"] = df_gt.count(axis=1)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all other columns but name and corner num\n",
    "df_tf = df_tf[[\"filename\", \"tf-num-corners\"]]\n",
    "df_ff = df_ff[[\"filename\", \"ff-num-corners\"]]\n",
    "df_gt = df_gt[[\"filename\", \"gt-num-corners\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on filename\n",
    "corner_nums = df_gt.merge(df_tf, on=\"filename\").merge(df_ff, on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MAE compared to GTs\n",
    "error_tf = mean_absolute_error(corner_nums[\"gt-num-corners\"], corner_nums[\"tf-num-corners\"])\n",
    "error_ff = mean_absolute_error(corner_nums[\"gt-num-corners\"], corner_nums[\"ff-num-corners\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309859154929577\n",
      "1.1549295774647887\n"
     ]
    }
   ],
   "source": [
    "print(error_tf)\n",
    "print(error_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=48.0, pvalue=0.0002451354174095733)\n"
     ]
    }
   ],
   "source": [
    "tf_error_dist = np.abs(corner_nums[\"gt-num-corners\"]-corner_nums[\"tf-num-corners\"])\n",
    "ff_error_dist = np.abs(corner_nums[\"gt-num-corners\"]-corner_nums[\"ff-num-corners\"])\n",
    "\n",
    "res = wilcoxon(tf_error_dist, ff_error_dist)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare error of corner points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = df_tf_input[[\"filename\", \"height\", \"width\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "df_ff = df_ff_input[[\"filename\", \"height\", \"width\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "df_gt = df_gt_input[[\"filename\", \"height\", \"width\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]]\n",
    "\n",
    "df_tf = df_tf.replace('FAILED', np.nan, regex=True)\n",
    "df_ff = df_ff.replace('FAILED', np.nan, regex=True)\n",
    "\n",
    "# df_tf[\"tf-num-corners\"] = df_tf.count(axis=1)-1\n",
    "# df_tf[\"gt-num-corners\"] = df_gt.count(axis=1)-1\n",
    "# df_ff[\"ff-num-corners\"] = df_ff.count(axis=1)-1\n",
    "# df_ff[\"gt-num-corners\"] = df_tf[\"gt-num-corners\"]\n",
    "# df_gt[\"gt-num-corners\"] = df_tf[\"gt-num-corners\"]\n",
    "# df_gt[\"tf-num-corners\"] = df_tf[\"tf-num-corners\"]\n",
    "# df_gt[\"ff-num-corners\"] = df_ff[\"ff-num-corners\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make GTs on same scale as predictions\n",
    "scaled_gt = df_gt.copy()\n",
    "\n",
    "for i in range(len(scaled_gt)):\n",
    "    mult = df_tf.loc[i, [\"width\"]] / scaled_gt.loc[i, [\"width\"]]\n",
    "    mult = mult[\"width\"]\n",
    "    \n",
    "    scaled_gt.loc[i, [\"height\"]] = scaled_gt.loc[i, [\"height\"]] * mult\n",
    "    scaled_gt.loc[i, [\"width\"]] = scaled_gt.loc[i, [\"width\"]] * mult\n",
    "    scaled_gt.loc[i, [\"corner-1\"]] = scaled_gt.loc[i, [\"corner-1\"]] * mult\n",
    "    scaled_gt.loc[i, [\"corner-2\"]] = scaled_gt.loc[i, [\"corner-2\"]] * mult\n",
    "    scaled_gt.loc[i, [\"corner-3\"]] = scaled_gt.loc[i, [\"corner-3\"]] * mult\n",
    "    scaled_gt.loc[i, [\"corner-4\"]] = scaled_gt.loc[i, [\"corner-4\"]] * mult\n",
    "    scaled_gt.loc[i, [\"corner-5\"]] = scaled_gt.loc[i, [\"corner-5\"]] * mult\n",
    "\n",
    "scaled_gt = scaled_gt.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only look at rows where num of corners is the same\n",
    "# df_tf = df_tf.drop(df_tf[df_tf[\"tf-num-corners\"] != df_tf[\"gt-num-corners\"]].index)\n",
    "# gt_tf = df_gt.drop(df_gt[df_gt[\"tf-num-corners\"] != df_gt[\"gt-num-corners\"]].index)\n",
    "# df_ff = df_ff.drop(df_ff[df_ff[\"ff-num-corners\"] != df_ff[\"gt-num-corners\"]].index)\n",
    "# gt_ff = df_gt.drop(df_gt[df_gt[\"ff-num-corners\"] != df_gt[\"gt-num-corners\"]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(df_gt, df_tf):\n",
    "    output = []\n",
    "    for i in range(df_gt.shape[0]):\n",
    "        gt_np = df_gt[[\"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]].loc[i].dropna().to_numpy()\n",
    "        tf_np = df_tf[[\"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]].loc[i].dropna().to_numpy()\n",
    "\n",
    "        sub_mat = []\n",
    "        for j in range(len(tf_np)):\n",
    "            sub_mat.append(np.abs(gt_np - tf_np[j]))\n",
    "        sub_mat = np.array(sub_mat)\n",
    "\n",
    "        links = []\n",
    "        for j in range(min(len(tf_np), len(gt_np))):\n",
    "            smallest = np.amin(sub_mat)\n",
    "            ind_0, ind_1 = np.where(sub_mat == smallest)\n",
    "            links.append([ind_0[0], ind_1[0]])\n",
    "            sub_mat[:, ind_1[0]] = 1000000\n",
    "        output.append(links)\n",
    "\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kim\\anaconda3\\envs\\analysis\\lib\\site-packages\\ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# do the below on each row of df_tf and df_ff\n",
    "tf_corner_ind_links = find_corners(scaled_gt, df_tf)\n",
    "ff_corner_ind_links = find_corners(scaled_gt, df_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use inds to create new lists of corners in same order as GT\n",
    "# new_tf = pd.DataFrame(data=[], columns=[\"filename\", \"height\", \"width\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"])\n",
    "# new_tf[[\"filename\", \"height\", \"width\"]] = df_tf[[\"filename\", \"height\", \"width\"]]\n",
    "\n",
    "# for i in range(len(new_tf)):\n",
    "#     vals = np.empty(5)\n",
    "#     vals[:] = np.nan\n",
    "#     for j in range(len(tf_corner_ind_links[i])):\n",
    "#         tf_val = df_tf.loc[i, f\"corner-{tf_corner_ind_links[i][j][0]+1}\"]\n",
    "#         vals[tf_corner_ind_links[i][j][1]] = tf_val\n",
    "\n",
    "#     new_tf.loc[i, [\"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use inds to create new lists of corners in same order as GT\n",
    "def get_ordered_preds(old, corner_ind_links):\n",
    "    new = pd.DataFrame(data=[], columns=[\"filename\", \"height\", \"width\", \"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"])\n",
    "    new[[\"filename\", \"height\", \"width\"]] = old[[\"filename\", \"height\", \"width\"]]\n",
    "\n",
    "    for i in range(len(new)):\n",
    "        vals = np.empty(5)\n",
    "        vals[:] = np.nan\n",
    "        for j in range(len(corner_ind_links[i])):\n",
    "            pred_val = old.loc[i, f\"corner-{corner_ind_links[i][j][0]+1}\"]\n",
    "            vals[corner_ind_links[i][j][1]] = pred_val\n",
    "\n",
    "        new.loc[i, [\"corner-1\", \"corner-2\", \"corner-3\", \"corner-4\", \"corner-5\"]] = vals\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tf = get_ordered_preds(df_tf, tf_corner_ind_links)\n",
    "new_ff = get_ordered_preds(df_ff, ff_corner_ind_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc error for each corner\n",
    "tf_err = new_tf[[\"filename\"]]\n",
    "ff_err = new_ff[[\"filename\"]]\n",
    "\n",
    "for i in range(5):\n",
    "    tf = abs(new_tf[[f\"corner-{i+1}\"]] - scaled_gt[[f\"corner-{i+1}\"]])\n",
    "    tf_err = tf_err.assign(**tf)\n",
    "\n",
    "    ff = abs(new_ff[[f\"corner-{i+1}\"]] - scaled_gt[[f\"corner-{i+1}\"]])\n",
    "    ff_err = ff_err.assign(**ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tf_err)):\n",
    "    for j in range(5):\n",
    "        # if tf_err.loc[i, [f\"corner-{j+1}\"]].values[0] != np.nan:\n",
    "        # print(tf_err.loc[i, [f\"corner-{j+1}\"]].values[0])\n",
    "        tf_err.at[i, [f\"corner-{j+1}\"]] = (tf_err.loc[i, [f\"corner-{j+1}\"]].values[0] / scaled_gt.loc[i, [\"width\"]].values[0]) * 100\n",
    "        ff_err.at[i, [f\"corner-{j+1}\"]] = (ff_err.loc[i, [f\"corner-{j+1}\"]].values[0] / scaled_gt.loc[i, [\"width\"]].values[0]) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_err_list = np.concatenate((tf_err[\"corner-1\"], tf_err[\"corner-2\"],\n",
    "                            tf_err[\"corner-3\"], tf_err[\"corner-4\"],\n",
    "                            tf_err[\"corner-5\"]))\n",
    "tf_err_list = tf_err_list[~np.isnan(tf_err_list.astype(float))]\n",
    "\n",
    "ff_err_list = np.concatenate((ff_err[\"corner-1\"], ff_err[\"corner-2\"],\n",
    "                            ff_err[\"corner-3\"], ff_err[\"corner-4\"],\n",
    "                            ff_err[\"corner-5\"]))\n",
    "ff_err_list = ff_err_list[~np.isnan(ff_err_list.astype(float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mean_err = 13.560248183732005\n",
      "ff_mean_err = 15.264777677965101\n"
     ]
    }
   ],
   "source": [
    "tf_mean_err = np.mean(tf_err_list)\n",
    "ff_mean_err = np.mean(ff_err_list)\n",
    "\n",
    "print(f\"tf_mean_err = {tf_mean_err}\")\n",
    "print(f\"ff_mean_err = {ff_mean_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error of corner-floor intersection points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = df_ft_input[[\"filename\", \"co-fl-in-1\", \"co-fl-in-2\", \"co-fl-in-3\", \"co-fl-in-4\", \"co-fl-in-5\"]]\n",
    "df_gt = df_gt_input[[\"filename\", \"co-fl-in-1\", \"co-fl-in-2\", \"co-fl-in-3\", \"co-fl-in-4\", \"co-fl-in-5\"]]\n",
    "\n",
    "df_ft = df_ft.replace('FAILED', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error\n",
    "\n",
    "# 30 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare wall coverage percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = df_tf_input[[\"filename\", \"wall-coverage-perc\"]]\n",
    "df_ft = df_ft_input[[\"filename\", \"wall-coverage-perc\"]]\n",
    "df_ff = df_ff_input[[\"filename\", \"wall-coverage-perc\"]]\n",
    "\n",
    "df_tf = df_tf.replace('FAILED', 0, regex=True)\n",
    "df_ft = df_ft.replace('FAILED', 0, regex=True)\n",
    "df_ff = df_ff.replace('FAILED', 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf[\"wall-coverage-perc\"] = df_tf[\"wall-coverage-perc\"].astype(float)\n",
    "df_ft[\"wall-coverage-perc\"] = df_ft[\"wall-coverage-perc\"].astype(float)\n",
    "df_ff[\"wall-coverage-perc\"] = df_ff[\"wall-coverage-perc\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount those where plain wall mask is used by removing 1s\n",
    "df_tf = df_tf.drop(df_tf[df_tf['wall-coverage-perc'] == float(1)].index)\n",
    "df_ft = df_ft.drop(df_ft[df_ft['wall-coverage-perc'] == float(1)].index)\n",
    "df_ff = df_ff.drop(df_ff[df_ff['wall-coverage-perc'] == float(1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mean = 0.9137844023469459\n",
      "ft_mean = 0.8236358285052049\n",
      "ff_mean = 0.9166521378509982\n"
     ]
    }
   ],
   "source": [
    "tf_mean = df_tf[[\"wall-coverage-perc\"]].mean(numeric_only=True)[0]\n",
    "ft_mean = df_ft[[\"wall-coverage-perc\"]].mean(numeric_only=True)[0]\n",
    "ff_mean = df_ff[[\"wall-coverage-perc\"]].mean(numeric_only=True)[0]\n",
    "\n",
    "print(f\"tf_mean = {tf_mean}\")\n",
    "print(f\"ft_mean = {ft_mean}\")\n",
    "print(f\"ff_mean = {ff_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_1 = MannwhitneyuResult(statistic=1854.5, pvalue=0.4767893960305616)\n",
      "res_2 = MannwhitneyuResult(statistic=1550.0, pvalue=0.5517142360306657)\n",
      "res_3 = MannwhitneyuResult(statistic=1173.5, pvalue=0.248407364344584)\n"
     ]
    }
   ],
   "source": [
    "res_1 = mannwhitneyu(df_tf[\"wall-coverage-perc\"], df_ft[\"wall-coverage-perc\"])\n",
    "res_2 = mannwhitneyu(df_tf[\"wall-coverage-perc\"], df_ff[\"wall-coverage-perc\"])\n",
    "res_3 = mannwhitneyu(df_ft[\"wall-coverage-perc\"], df_ff[\"wall-coverage-perc\"])\n",
    "\n",
    "print(f\"res_1 = {res_1}\")\n",
    "print(f\"res_2 = {res_2}\")\n",
    "print(f\"res_3 = {res_3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
