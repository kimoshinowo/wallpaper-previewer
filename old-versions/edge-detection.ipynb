{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Setup"]},{"cell_type":"markdown","metadata":{},"source":["## Installs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16807,"status":"ok","timestamp":1700649874437,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"GIoo5vcfiqpF","outputId":"b10a286b-4fd5-4420-8fdc-659a8072a6f7"},"outputs":[],"source":["# Segmentation\n","# ! pip install --upgrade mxnet\n","# ! pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n","# ! pip install --upgrade gluoncv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Edge detection\n","# ! conda install scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Depth estimation\n","# ! pip install -q transformers"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"elapsed":247,"status":"error","timestamp":1700649954416,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"qin4eTO9iKiG","outputId":"4c7e8c7c-34ef-49aa-aea1-ed9807fb3f8f"},"outputs":[],"source":["# Segmentation\n","import numpy as np\n","\n","import mxnet as mx\n","from mxnet import image\n","from mxnet.gluon.data.vision import transforms\n","\n","import gluoncv\n","from gluoncv.utils.viz import get_color_pallete\n","from gluoncv.data.transforms.presets.segmentation import test_transform\n","\n","from matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","\n","import PIL.Image as pil\n","\n","# using cpu\n","ctx = mx.cpu(0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Edge detection\n","from skimage.feature import canny\n","from matplotlib import cm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Depth estimation\n","from transformers import pipeline\n","import requests"]},{"cell_type":"markdown","metadata":{"id":"7RanapCSiKiJ"},"source":["# Read and Transform File"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1700649532587,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"GSgMVSRSiKiL"},"outputs":[],"source":["filename = 'images/inputs/rooms/empty-room.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1700649532587,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"hVOVqgq8iKiM"},"outputs":[],"source":["img = image.imread(filename)\n","plt.imshow(img.asnumpy())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1700649532588,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"1KQjUv4JiKiM"},"outputs":[],"source":["img_t = test_transform(img, ctx)\n","img_t.shape"]},{"cell_type":"markdown","metadata":{"id":"IYVmV6aJiKiN"},"source":["# Semantic Segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700649532817,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"Q6GyxK1qiKiN"},"outputs":[],"source":["semantic_seg_model_psp = model = gluoncv.model_zoo.get_model('psp_resnet101_ade', pretrained=True)\n","semantic_seg_model_deeplab =gluoncv.model_zoo.get_model('deeplab_resnet101_ade', pretrained=True)\n","semantic_seg_model_fcn = gluoncv.model_zoo.get_model('fcn_resnet101_voc', pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700649532817,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"qExQslHPiKiO"},"outputs":[],"source":["output = semantic_seg_model_psp.predict(img_t)\n","predict = mx.nd.squeeze(mx.nd.argmax(output, 1)).asnumpy()\n","\n","mask = get_color_pallete(predict, 'ade20k')\n","mask.save('images/outputs/segmentation-output.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700649532818,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"1c6qF_t9iKiP"},"outputs":[],"source":["mmask = mpimg.imread('images/outputs/segmentation-output.png')\n","plt.imshow(mmask)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"V71C4vteiKiP"},"source":["### Isolate walls"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1700649532818,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"ypDnKxxMiKiQ"},"outputs":[],"source":["labs = []\n","\n","for i in range(mmask.shape[0]):\n","    row = []\n","    for j in range(mmask.shape[1]):\n","        row.append(\",\".join(mmask[i, j].astype(str)))\n","    labs.append(row)\n","\n","labs = np.array(labs)\n","labs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1700649532819,"user":{"displayName":"Kim Oshinowo","userId":"03566108594766664656"},"user_tz":0},"id":"pNh2j8SIiKiQ"},"outputs":[],"source":["ind_0, ind_1 = np.where(labs != \"0.47058824,0.47058824,0.47058824,1.0\")\n","ind_2, ind_3 = np.where(labs == \"0.47058824,0.47058824,0.47058824,1.0\")"]},{"cell_type":"markdown","metadata":{"id":"l_oyBNY-iKiR"},"source":["# Edge Detection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","\n","# Read image\n","image = cv2.imread(filename)\n","\n","# Convert image to grayscale\n","blur = cv2.blur(image, (3, 3))\n","gray = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)\n"," \n","# Use canny edge detection\n","edges = cv2.Canny(gray,15,50,apertureSize=3)\n","\n","edge_map = pil.fromarray(edges)\n","edge_map.save('images/outputs/edge-detection-output.png')\n","\n","plt.imshow(edge_map, cmap=cm.gray)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Combining Images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Combine edge map and segmentation map\n","edge_map_array = np.asarray(edge_map.convert('RGB'))\n","segmented_edges = np.empty( (edge_map_array.shape[0], edge_map_array.shape[1], 3) )\n","segmented_edges[:] = np.nan\n","segmented_edges[ind_2, ind_3] = edge_map_array[ind_2, ind_3]\n","plt.imshow(segmented_edges)\n","segmented_edges = segmented_edges.astype(dtype=np.uint8)\n","\n","segmented_edges = pil.fromarray(segmented_edges)\n","segmented_edges.save('images/outputs/segmented-edges.png')\n","# plt.imshow(edge_map)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im = cv2.imread('images/outputs/segmented-edges.png')\n","imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","ret, edge_thresh = cv2.threshold(imgray, 0, 1, 0)\n","\n","# thresh = cv.adaptiveThreshold(imgray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 3, 1)\n","\n","# kernel = cv.getStructuringElement(cv.MORPH_RECT,(10, 10))\n","# thresh = cv.morphologyEx(thresh, cv.MORPH_OPEN,kernel)\n","edge_contours, _ = cv2.findContours(edge_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","plt.imshow(edge_thresh)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://stackoverflow.com/questions/44127342/detect-card-minarea-quadrilateral-from-contour-opencv?\n","# fbclid=IwAR3A4AjuD7x8dp07ln4sPJYFyMR1m_u1sb-m1hAbdzc9epuyZcCh5yaij8Y\n","\n","im_2 = np.zeros( (im.shape[0], im.shape[1], 3) )\n","\n","final_cnt = []\n","\n","for cnt in edge_contours:\n","    x1,y1 = cnt[0][0]\n","\n","    if cv2.arcLength(cnt,True) > 200:\n","        im_2 = cv2.drawContours(im_2, [cnt], -1, (0,0,255), 2)\n","\n","plt.imshow(im_2)\n","final_cnt = np.array(final_cnt)\n","\n","im_2 = pil.fromarray(im_2.astype(dtype=np.uint8))\n","im_2.save('images/outputs/contours.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hough transform on segmented edges\n","\n","# Read image\n","test = np.asarray(segmented_edges)\n","blank_image = np.empty( (test.shape[0], test.shape[1], 3) )\n","test = cv2.imread('images/outputs/segmented-edges.png')\n","test = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)\n","\n","# Apply HoughLinesP method to \n","# to directly obtain line end points\n","lines_list =[]\n","lines = cv2.HoughLinesP(\n","            test, # Input edge image\n","            1, # Distance resolution in pixels\n","            np.pi/180, # Angle resolution in radians\n","            threshold=50, # Min number of votes for valid line\n","            minLineLength=45, # Min allowed length of line\n","            maxLineGap=20 # Max allowed gap between line for joining them\n","            )\n"," \n","# Iterate over points\n","for points in lines:\n","      # Extracted points nested in the list\n","    x1,y1,x2,y2=points[0]\n","    # Draw the lines joing the points\n","    # On the original image\n","    cv2.line(blank_image,(x1,y1),(x2,y2),(0,0,255),2)\n","    # Maintain a simples lookup list for points\n","    lines_list.append([(x1,y1),(x2,y2)])\n","     \n","# Save the result image\n","cv2.imwrite('images/outputs/hough-output.png',blank_image)\n","plt.imshow(blank_image)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://www.youtube.com/watch?v=veoz_46gOkc\n","hough_img = cv2.imread('images/outputs/hough-output.png')\n","kernel = np.ones((20,1), np.uint8)\n","vertical_lines = cv2.erode(hough_img, kernel, iterations=1)\n","cv2.imwrite('images/outputs/vertical-hough-ouput.png',vertical_lines)\n","\n","plt.imshow(vertical_lines)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Finding Geometry"]},{"cell_type":"markdown","metadata":{},"source":["##### Extracting Geometry"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im = cv2.imread('images/outputs/contours.png')\n","assert im is not None, \"file could not be read, check with os.path.exists()\"\n","imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","ret, thresh = cv2.threshold(imgray, 0, 1, 0)\n","\n","# thresh = cv2.adaptiveThreshold(imgray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 1)\n","\n","# kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(10, 10))\n","# thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN,kernel)\n","contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_2 = im.copy()\n","final_cnt = []\n","\n","for cnt in contours:\n","    x1,y1 = cnt[0][0]\n","    approx = cv2.approxPolyDP(cnt, 0.02*cv2.arcLength(cnt, True), False)\n","\n","    # cv.putText(im_2, 'Rectangle', (x1, y1), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n","    im_2 = cv2.drawContours(im_2, [cnt], -1, (0,0,255), 3)\n","    plt.scatter(approx[:, 0, 0], approx[:, 0, 1], color=\"r\")\n","    final_cnt.append(approx[:, 0, :])\n","    \n","plt.imshow(im_2)\n","final_cnt = np.array(final_cnt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(len(final_cnt)):\n","    data = np.append(final_cnt[i], final_cnt[i][0]).reshape(-1, 2)\n","    \n","    plt.plot(np.array(data)[:, 0], -np.array(data)[:, 1])\n","\n","corner_inds = [118, 442]\n","plt.scatter(corner_inds, [-150, -150])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["corner_adj_geom = []\n","\n","for i in range(len(final_cnt)):\n","    data = np.array(final_cnt[i])[:, 0]\n","    limit = 5\n","    \n","    diff_1 = np.sum(np.abs(data.copy() - corner_inds[0]) <= limit)\n","    diff_2 = np.sum(np.abs(data.copy() - corner_inds[1]) <= limit)\n","    \n","    if diff_1 >= 2 or diff_2 >= 2:\n","        corner_adj_geom.append(final_cnt[i])\n","        \n","for i in range(len(corner_adj_geom)):\n","    data = np.append(corner_adj_geom[i], corner_adj_geom[i][0]).reshape(-1, 2)\n","    \n","    plt.plot(np.array(data)[:, 0], -np.array(data)[:, 1])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
