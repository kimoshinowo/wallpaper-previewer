{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image as pil\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import wilcoxon, shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom methods\n",
    "import general_methods\n",
    "import semantic_segmentation\n",
    "import edge_detection\n",
    "import depth_estimation\n",
    "import geometry\n",
    "import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing & results gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pre-trained models\n",
    "seg_model = semantic_segmentation.get_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_and_edge_corners(input_pil, input_cv2, walls, height, width, other):\n",
    "    # Depth estimation\n",
    "    depth_image = depth_estimation.estimate_depth(input_pil)\n",
    "\n",
    "    # Edge detection\n",
    "    edge_map = edge_detection.detect_edges(input_cv2)\n",
    "    segmented_edges = edge_detection.get_segmented_edges(edge_map, walls)\n",
    "\n",
    "    # Find corners\n",
    "    hough_img = edge_detection.hough_transform(segmented_edges, height, 50, 0.03, 0.02)\n",
    "    vertical_lines = edge_detection.get_vertical_lines(hough_img)\n",
    "    hough_colours = general_methods.get_labels_string(vertical_lines, vertical_lines.shape[0])\n",
    "    hough_corners = edge_detection.get_hough_corners(hough_colours)\n",
    "    mean_depth = depth_estimation.get_mean_depths(depth_image, other)\n",
    "    matrix = general_methods.get_matrix(mean_depth)\n",
    "    matrix_corners = depth_estimation.get_harris_corners(matrix)\n",
    "    harris_colours = general_methods.get_labels_string(matrix_corners, matrix_corners.shape[0])\n",
    "    _, harris_corners = np.where(harris_colours == \"255,0,0\")\n",
    "    corner_inds = geometry.find_corners(hough_corners, harris_corners, width)\n",
    "\n",
    "    return corner_inds\n",
    "\n",
    "def corner_detection(labels, height, width, input_cv2, walls, input_pil, other):\n",
    "    ceiling_x, _ = np.where(labels == \"0.47058824,0.47058824,0.3137255,1.0\")\n",
    "\n",
    "    if ceiling_x.size > (0.01 * (height * width)):\n",
    "        non_ceil_x, non_ceil_y = np.where((labels != \"0.47058824,0.47058824,0.47058824,1.0\") & (labels != \"0.47058824,0.47058824,0.3137255,1.0\"))\n",
    "        non_ceil = np.array([non_ceil_x, non_ceil_y])\n",
    "\n",
    "        input_copy = np.ones((input_cv2.shape[0], input_cv2.shape[1], 3))\n",
    "        input_copy = input_copy.astype(float)\n",
    "        input_copy[non_ceil[0], non_ceil[1]] = np.array([255, 255, 255], dtype=float)\n",
    "        input_copy[walls[0], walls[1]] = np.array([255, 255, 255], dtype=float)\n",
    "        input_copy = np.clip(input_copy, 0, 255)\n",
    "\n",
    "        segmented_input_2 = input_copy.astype(np.uint8)\n",
    "\n",
    "        for i in range(input_cv2.shape[1]):\n",
    "            for j in range(input_cv2.shape[0]-1, -1, -1):\n",
    "                if np.array_equal(segmented_input_2[j][i], [1, 1, 1]):\n",
    "                    segmented_input_2[:j, i] = np.array([1, 1, 1], dtype=float)\n",
    "                    break\n",
    "\n",
    "        edge_map = edge_detection.detect_edges(segmented_input_2)\n",
    "        edge_map = np.asarray(edge_map.convert(\"RGB\"))\n",
    "\n",
    "        hough_img = edge_detection.hough_transform(edge_map, input_cv2.shape[0], 10, 0.001, 0.5)\n",
    "        corners = depth_estimation.get_harris_corners(hough_img)\n",
    "        labels_red = general_methods.get_labels_string(corners, 40)\n",
    "        red = general_methods.find_colour_indices(labels_red, \"255.0,0.0,0.0\")\n",
    "        \n",
    "        temp2 = corners.copy()\n",
    "        temp2[red[0], red[1]] = np.array([0, 0, 0], dtype=float)\n",
    "\n",
    "        ceiling_colours = general_methods.get_labels_string(temp2, temp2.shape[0])\n",
    "        _, ceiling_corners = np.where(ceiling_colours == \"255.0,0.0,0.0\")\n",
    "        corner_inds = geometry.find_corners(ceiling_corners, ceiling_corners, width)\n",
    "\n",
    "        if corner_inds.size == 0:\n",
    "            corner_inds = depth_and_edge_corners(input_pil, input_cv2, walls, height, width, other)\n",
    "    else:\n",
    "        corner_inds = depth_and_edge_corners(input_pil, input_cv2, walls, height, width, other)\n",
    "    \n",
    "    return corner_inds\n",
    "\n",
    "def pipeline(filename, wallpaper_filename, corners = None):\n",
    "    input_pil = general_methods.import_and_resize(filename)\n",
    "    input_img = general_methods.import_mx_image(\"images/outputs/intermediate-outputs/resized-input.png\")\n",
    "    input_cv2 = general_methods.import_cv2_image(\"images/outputs/intermediate-outputs/resized-input.png\")\n",
    "    height = input_cv2.shape[0]\n",
    "    width = input_cv2.shape[1]\n",
    "    size = (width, height)\n",
    "\n",
    "    # Segmentation\n",
    "    seg_model = semantic_segmentation.get_pretrained_model()\n",
    "    mmask = semantic_segmentation.get_segementation(input_img, seg_model)\n",
    "    labels = general_methods.get_labels_string(mmask, mmask.shape[0])\n",
    "    walls = general_methods.find_colour_indices(labels, \"0.47058824,0.47058824,0.47058824,1.0\")\n",
    "    other = general_methods.find_not_colour_indices(labels, \"0.47058824,0.47058824,0.47058824,1.0\")\n",
    "    segmented_input = semantic_segmentation.remove_inds(input_img, [other], [0, 0, 0])\n",
    "\n",
    "    if corners is None:\n",
    "        corner_inds = corner_detection(labels, height, width, input_cv2, walls, input_pil, other)\n",
    "    else:\n",
    "        corner_inds = np.array([int(corner) for corner in corners.split()])\n",
    "\n",
    "    only_walls = geometry.create_wall_corner_map(segmented_input, other, walls, corner_inds)\n",
    "\n",
    "    # Find room geometry\n",
    "    contours = geometry.find_contours(only_walls)\n",
    "    corner_adj_geom = geometry.find_walls(contours, corner_inds)\n",
    "    new_geom = geometry.find_quadrilaterals(corner_adj_geom, width)\n",
    "    new_corner_geom = geometry.remove_nested_geometry(new_geom)\n",
    "    new_corner_geom = geometry.move_edges_to_corners(new_corner_geom, corner_inds, width)\n",
    "\n",
    "    # Perspective transform\n",
    "    wallpaper = general_methods.import_cv2_image(wallpaper_filename)\n",
    "    result_1, result_2 = transforms.get_transformed_wallpaper(new_corner_geom, height, width, size, wallpaper)\n",
    "\n",
    "    # Create final image\n",
    "    final_mask, extra_mask = transforms.get_wall_mask(new_corner_geom, height, width, walls)\n",
    "\n",
    "    return final_mask\n",
    "    # final_output_1, final_output_2 = transforms.combine_wallpaper_and_input(input_cv2, final_mask, extra_mask, result_1, result_2, walls)\n",
    " \n",
    "    # return final_output_1, final_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = \"images/inputs/rooms/seg-test-set/\"\n",
    " \n",
    "for image in listdir(folder_dir):\n",
    "    print(image)\n",
    "    filename = \"images/inputs/rooms/seg-test-set/\" + image\n",
    "    output = pipeline(filename, \"images/inputs/wallpaper/check-even.jpg\")\n",
    "    height = output.shape[0]\n",
    "    width = output.shape[1]\n",
    "    new = np.zeros((height, width, 3))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if output[i][j] == 0:\n",
    "                new[i][j] = [0, 0, 0]\n",
    "            if output[i][j] != 0:\n",
    "                new[i][j] = [120, 120, 120]\n",
    "    cv2.imwrite(\"images/outputs/geom-seg/\" + image, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to perform segmentation and return black image with only walls in grey\n",
    "\n",
    "def wall_segmentation(filename):\n",
    "    input_pil = general_methods.import_and_resize(filename)\n",
    "    input_img = general_methods.import_mx_image(filename)\n",
    "    input_cv2 = general_methods.import_cv2_image(filename)\n",
    "    height = input_cv2.shape[0]\n",
    "    width = input_cv2.shape[1]\n",
    "    size = (width, height)\n",
    "\n",
    "    # Segmentation\n",
    "    mmask = semantic_segmentation.get_segementation(input_img, seg_model)\n",
    "    labels = general_methods.get_labels_string(mmask, mmask.shape[0])\n",
    "    walls = general_methods.find_colour_indices(labels, \"0.47058824,0.47058824,0.47058824,1.0\")\n",
    "    black = np.zeros((height, width, 3))\n",
    "    segmented_input = semantic_segmentation.remove_inds(black, [walls], [120, 120, 120])\n",
    "\n",
    "    return segmented_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change seg images so only walls are grey\n",
    "\n",
    "folder_dir = \"images/seg-images/\"\n",
    " \n",
    "for image in listdir(folder_dir):\n",
    "    filename = \"images/seg-images/\" + image\n",
    "    print(image)\n",
    "    input_cv2 = general_methods.import_cv2_image(filename)\n",
    "    img = input_cv2.copy()\n",
    "    height = input_cv2.shape[0]\n",
    "    width = input_cv2.shape[1]\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i][j][0] == 0:\n",
    "                img[i][j] = [0, 0, 0]\n",
    "            if img[i][j][0] != 0:\n",
    "                img[i][j] = [120, 120, 120]\n",
    "    \n",
    "    cv2.imwrite(\"images/seg-images-after/\" + image, img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADE_val_00000079_wall_seg.png\n"
     ]
    }
   ],
   "source": [
    "for image in listdir(\"data-collection/groundtruths/segmentation/\"):\n",
    "    filename = \"data-collection/groundtruths/segmentation/\" + image\n",
    "    image_name = image[:-13]\n",
    "    print(image)\n",
    "    input_cv2 = general_methods.import_cv2_image(filename)\n",
    "    height = input_cv2.shape[0]\n",
    "    width = input_cv2.shape[1]\n",
    "\n",
    "    input_pil = pil.open(\"images/outputs/segmentation/\" + image_name + \".jpg\")\n",
    "    input_pil = input_pil.resize((width, height))\n",
    "    input_pil.save(\"images/outputs/segmentation-resized/\" + image_name + \".jpg\")\n",
    "\n",
    "    input_pil = pil.open(\"images/seg-images/\" + image_name + \".png\")\n",
    "    input_pil = input_pil.resize((width, height))\n",
    "    input_pil.save(\"images/seg-images-resized/\" + image_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in listdir(\"images/outputs/segmentation/\"):\n",
    "    filename = \"images/outputs/segmentation/\" + image\n",
    "    image_name = image[:-4]\n",
    "    print(image)\n",
    "    input_cv2 = general_methods.import_cv2_image(filename)\n",
    "    height = input_cv2.shape[0]\n",
    "    width = input_cv2.shape[1]\n",
    "\n",
    "    try:\n",
    "        img1 = cv2.imread(\"images/seg-images/\" + image_name + \".png\")\n",
    "        img1 = cv2.resize(img1,(width, height),fx=0, fy=0, interpolation = cv2.INTER_NEAREST)\n",
    "        cv2.imwrite(\"images/seg-images-resized/\" + image_name + \".png\", img1)\n",
    "    except:\n",
    "        print(image_name + \" doesn't exist\")\n",
    "\n",
    "    img2 = cv2.imread(\"data-collection/groundtruths/segmentation/\" + image_name + \"_wall_seg.png\")\n",
    "    img2 = cv2.resize(img2,(width, height),fx=0, fy=0, interpolation = cv2.INTER_NEAREST)\n",
    "    cv2.imwrite(\"data-collection/groundtruths/segmentation-resized/\" + image_name + \"_wall_seg.png\", img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = general_methods.import_cv2_image(\"images/outputs/segmentation/ADE_val_00000079.jpg\")\n",
    "wiz = general_methods.import_cv2_image(\"images/seg-images-after/ADE_val_00000079.png\")\n",
    "gt = general_methods.import_cv2_image(\"data-collection/groundtruths/segmentation-resized/ADE_val_00000079_wall_seg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iuo(image_1, image_2):\n",
    "    # https://towardsdatascience.com/intersection-over-union-iou-calculation-for-evaluating-an-image-segmentation-model-8b22e2e84686\n",
    "    intersection = np.logical_and(image_1, image_2)\n",
    "    union = np.logical_or(image_1, image_2)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[], columns=[\"Image_name\", \"Pipeline_GT_IOU\", \"Wizart_GT_IOU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in listdir(\"images/outputs/segmentation/\"):\n",
    "    filename = \"images/outputs/segmentation/\" + image\n",
    "    image_name = image[:-4]\n",
    "    pl = general_methods.import_cv2_image(filename)\n",
    "    gt = general_methods.import_cv2_image(\"data-collection/groundtruths/segmentation-resized/\" + image_name + \"_wall_seg.png\")\n",
    "    pl_iou = round(get_iuo(gt, pl) * 100, 1)\n",
    "\n",
    "    try:\n",
    "        wiz = general_methods.import_cv2_image(\"images/seg-images-resized/\" + image_name + \".png\")\n",
    "        wiz_iou = round(get_iuo(gt, wiz) * 100, 1)\n",
    "    except:\n",
    "        wiz_iou = float(\"nan\")\n",
    "\n",
    "    new_data = [image_name, pl_iou, wiz_iou]\n",
    "    df.loc[len(df)] = new_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_mean = 82.79545454545453\n",
      "pipeline_std = 10.832572640935378\n",
      "\n",
      "wizart_mean = 76.81052631578947\n",
      "wizart_std = 13.223112228700257\n"
     ]
    }
   ],
   "source": [
    "# Average wall coverage percentage for both\n",
    "pipeline_mean = df[\"Pipeline_GT_IOU\"].mean()\n",
    "wizart_mean = df[\"Wizart_GT_IOU\"].mean()\n",
    "\n",
    "# Standard deviation for both\n",
    "pipeline_std = df[\"Pipeline_GT_IOU\"].std()\n",
    "wizart_std = df[\"Wizart_GT_IOU\"].std()\n",
    "\n",
    "print(f\"pipeline_mean = {pipeline_mean}\")\n",
    "print(f\"pipeline_std = {pipeline_std}\\n\")\n",
    "print(f\"wizart_mean = {wizart_mean}\")\n",
    "print(f\"wizart_std = {wizart_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"Pipeline_GT_IOU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "9\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# How many was mine better in?\n",
    "pipeline_count = 0\n",
    "wizart_count = 0\n",
    "draw = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if (df.iloc[i][\"Pipeline_GT_IOU\"] > df.iloc[i][\"Wizart_GT_IOU\"]) or math.isnan(df.iloc[i][\"Wizart_GT_IOU\"]):\n",
    "        pipeline_count += 1\n",
    "    elif df.iloc[i][\"Pipeline_GT_IOU\"] < df.iloc[i][\"Wizart_GT_IOU\"]:\n",
    "        wizart_count += 1\n",
    "    else:\n",
    "        draw += 1\n",
    "\n",
    "print(pipeline_count)\n",
    "print(wizart_count)\n",
    "print(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan rows\n",
    "df_new = df.dropna()\n",
    "\n",
    "pipeline_np = df_new[\"Pipeline_GT_IOU\"].to_numpy()\n",
    "wizart_np = df_new[\"Wizart_GT_IOU\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.7533387541770935, pvalue=1.3337198652152438e-06)\n",
      "ShapiroResult(statistic=0.9200963973999023, pvalue=0.00989960040897131)\n",
      "WilcoxonResult(statistic=137.0, pvalue=0.0007078925705370894)\n"
     ]
    }
   ],
   "source": [
    "# Test both for Normality\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html#scipy.stats.shapiro\n",
    "# If p value less than 0.05 then it's not normally distributed\n",
    "norm_pipeline = shapiro(pipeline_np)\n",
    "norm_wizart = shapiro(wizart_np)\n",
    "\n",
    "print(norm_pipeline)\n",
    "print(norm_wizart)\n",
    "\n",
    "# Wilcoxon test (to test significance)\n",
    "res_1 = wilcoxon(pipeline_np, wizart_np)\n",
    "print(res_1)\n",
    "# Significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data-collection/outputs/segmentation-iou-2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
